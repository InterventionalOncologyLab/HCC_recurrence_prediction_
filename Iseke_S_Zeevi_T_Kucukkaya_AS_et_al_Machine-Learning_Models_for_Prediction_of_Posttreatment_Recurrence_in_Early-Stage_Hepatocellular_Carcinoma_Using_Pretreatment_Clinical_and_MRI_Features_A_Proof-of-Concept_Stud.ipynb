{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries_dict = {\n",
    "    'utility': [\n",
    "        'import os',\n",
    "        'import sys',\n",
    "        'import numpy as np',\n",
    "        'import pandas as pd',\n",
    "    ],\n",
    "        \n",
    "    'deep_learning':[\n",
    "        'import tensorflow as tf',\n",
    "        'import keras as k',\n",
    "    ],   \n",
    "        \n",
    "    'statistics':[\n",
    "        'import scipy as sp',\n",
    "    ],    \n",
    "        \n",
    "    'display':[\n",
    "        'from tqdm import tqdm_notebook',\n",
    "        'from IPython.core.display import display, HTML',\n",
    "    ],     \n",
    "    \n",
    "    'image_processing': [\n",
    "        'from PIL import Image',\n",
    "        'import cv2 as cv', \n",
    "        'import scipy.ndimage as ndi',\n",
    "        'from skimage import measure',\n",
    "        'from skimage import transform',\n",
    "    ],\n",
    "    \n",
    "    'medical_imaging': [\n",
    "        'import pydicom', \n",
    "        'import nibabel as nib', \n",
    "        'import dicom2nifti', \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_libraries(topics = ['utility']):\n",
    "    \n",
    "    if topics == 'all':\n",
    "        topics = list(libraries_dict.keys())\n",
    "    \n",
    "    libraries = [';'.join(libraries_dict[topic]) for topic in topics]\n",
    "    \n",
    "    return ';'.join(libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box_coordinate_dict(bounding_boxes, accession_number, sequence_name, rois = ['tumor']):\n",
    "    coordinate_dict = {}\n",
    "    \n",
    "    for roi in rois:\n",
    "\n",
    "        bounding_boxes_acc = bounding_boxes[(bounding_boxes['accession_number'] == accession_number) & (bounding_boxes['roi'] == roi)]\n",
    "        roi_indices = bounding_boxes_acc['roi_idx']\n",
    "\n",
    "        bounding_boxes_acc = bounding_boxes_acc[[col for col in bounding_boxes_acc.columns if sequence_name in col]]\n",
    "\n",
    "        if consider_biggest_slice_coordinates == False:\n",
    "            bounding_boxes_acc = bounding_boxes_acc.drop(columns = [col for col in bounding_boxes_acc.columns if 'big' in col])\n",
    "\n",
    "        bounding_boxes_acc.columns = bounding_boxes_acc.columns = [col.split('_')[-1][0] for col in bounding_boxes_acc.columns]\n",
    "\n",
    "        for roi_idx in range(len(roi_indices)):\n",
    "            coordinate_values_roi = pd.DataFrame(bounding_boxes_acc.iloc[roi_idx,:]).T\n",
    "            coordinate_values_roi = [coordinate_values_roi.loc[:,bounding_boxes_acc.columns == plane].values[0] for plane in bounding_box_planes]\n",
    "            coordinate_dict_roi = dict(zip(bounding_box_planes, coordinate_values_roi))\n",
    "\n",
    "            coordinate_dict[str(roi) + str(roi_idx)] = coordinate_dict_roi\n",
    "            \n",
    "    return coordinate_dict\n",
    "\n",
    "def extract_ROI(img, roi_coordinate_dict, bounding_boxes_delta_dictionary = None):\n",
    "    \n",
    "    for plane, coordinates in roi_coordinate_dict.items():\n",
    "        \n",
    "        try:\n",
    "            delta = bounding_boxes_delta_dictionary[plane].copy()   \n",
    "\n",
    "            delta[0] = roi_coordinate_dict[plane][0] if (roi_coordinate_dict[plane][0] - delta[0] < 0) else delta[0] \n",
    "            if plane == 'z': delta[1] = img.shape[0] - roi_coordinate_dict[plane][1] -1 if roi_coordinate_dict[plane][1] + delta[1] > img.shape[0] else delta[1] \n",
    "            if plane == 'y': delta[1] = img.shape[1] - roi_coordinate_dict[plane][1] -1 if roi_coordinate_dict[plane][1] + delta[1] > img.shape[1] else delta[1] \n",
    "            if plane == 'x': delta[1] = img.shape[2] - roi_coordinate_dict[plane][1] -1 if roi_coordinate_dict[plane][1] + delta[1] > img.shape[2] else delta[1] \n",
    "\n",
    "        except:\n",
    "            delta = 0\n",
    "        \n",
    "        if plane == 'z': img = img[range(roi_coordinate_dict['z'][0] - delta[0], roi_coordinate_dict['z'][1]+1 + delta[1]), :, :]\n",
    "        if plane == 'y': img = img[:, range(roi_coordinate_dict['y'][0] - delta[0], roi_coordinate_dict['y'][1]+1 + delta[1]), :]\n",
    "        if plane == 'x': img = img[:, :, range(roi_coordinate_dict['x'][0] - delta[0], roi_coordinate_dict['x'][1]+1 + delta[1])]\n",
    "\n",
    "    return img\n",
    "\n",
    "def pre_process_image_to_vgg(image):\n",
    "\n",
    "    image = np.swapaxes(image,0,2)\n",
    "    image = image.astype(np.float32)\n",
    "    image = cv.resize(image,(224,224))\n",
    "    image = preprocess_input(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def floor_dimenssions(image_list):\n",
    "    dimensions = pd.DataFrame([img.shape for img in image_list])\n",
    "    unique_dimensions, counts = np.unique(dimensions, axis = 0, return_counts = True)\n",
    "    min_dimensions = tuple(dimensions.min(axis = 0).values)\n",
    "    \n",
    "    return np.array(unique_dimensions), np.array(min_dimensions)\n",
    "\n",
    "\n",
    "def pool_intensities(img, n_slices_raw_image, slice_thickness_raw_image, slices_per_batch  = 10, overlap = 0, operator = 'iqr', method = 'relative', verbose = 0):\n",
    "    if method == 'relative':\n",
    "        depth_mm = slice_thickness_raw_image*n_slices_raw_image\n",
    "        slices_per_batch = depth_mm*(slices_per_batch)\n",
    "        slices_per_batch = int(np.round(a = slices_per_batch/slice_thickness_raw_image, decimals = 0))\n",
    "        overlap = depth_mm*(overlap)\n",
    "        overlap = int(np.round(a = overlap/slice_thickness_raw_image, decimals = 0))\n",
    "    \n",
    "    n_original_slices = img.shape[0]\n",
    "\n",
    "    start = 0\n",
    "    stop = slices_per_batch\n",
    "    batched_images = []\n",
    "    while True:\n",
    "        batched_images.append(img[start:stop])\n",
    "        start = start + slices_per_batch-overlap\n",
    "        stop = start + slices_per_batch\n",
    "        if (stop > n_original_slices) & (start < n_original_slices):\n",
    "            batched_images.append(img[start:n_original_slices])\n",
    "            break\n",
    "        \n",
    "        if (start == n_original_slices):\n",
    "            break\n",
    "            \n",
    "    if operator == 'iqr':\n",
    "        mips = np.array([np.percentile(b, q=0.75, axis = 0) - np.percentile(b, q=0.25, axis = 0) for b in batched_images])\n",
    "    \n",
    "    if verbose >0:\n",
    "        visualize_mri_slices(img_array = mips, ncols = 5, bounding_box_coordinates_dict = None)\n",
    "    return mips\n",
    "\n",
    "def get_pooled_image_sequences(key_values, images, filter_size, filter_overlap, pool_op):\n",
    "    images_pooled = []\n",
    "    for key in tqdm_notebook(key_values):    \n",
    "        seuquence_images = images[key].copy()\n",
    "        n_slices_raw_image = metadata_dicom_headers[metadata_dicom_headers[key_subject] == key]['depth_pixel'].values[0]\n",
    "        slice_thickness_raw_image = metadata_dicom_headers[metadata_dicom_headers[key_subject] == key]['slice_thickness'].values[0]\n",
    "        \n",
    "        seuquence_images_pooled = np.array([pool_intensities(img = img, slices_per_batch  = filter_size, overlap = filter_overlap, operator = pool_op, method = 'relative', n_slices_raw_image = n_slices_raw_image, slice_thickness_raw_image=slice_thickness_raw_image) for img in seuquence_images])\n",
    "\n",
    "        batched_sequences = np.array([seuquence_images_pooled[:,idx,:,:] for idx in range(seuquence_images_pooled.shape[1])])\n",
    "\n",
    "        images_pooled.append(np.stack(batched_sequences, axis = 0))\n",
    "        \n",
    "    return images_pooled\n",
    "\n",
    "\n",
    "def get_vgg_embeddings(images):\n",
    "    embeddings = []\n",
    "    for stacked_batches in tqdm_notebook(images):  \n",
    "        instance_embeddings = get_image_embeddings.predict(np.stack([pre_process_image_to_vgg(s) for s in list(stacked_batches)], axis = 0))\n",
    "        embeddings.append(instance_embeddings)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def get_patient_label(patient_date_recurrence, patient_date_followup, patient_date_treatment, T):\n",
    "    patient_time_to_recurrence = (patient_date_recurrence -patient_date_treatment).dt.days.values[0]\n",
    "    patient_followup_time = (patient_date_followup -patient_date_treatment).dt.days.values[0]\n",
    "\n",
    "    patient_recurrence = False if  np.isnan(patient_time_to_recurrence) else True\n",
    "    \n",
    "    if (patient_recurrence == True) & (patient_time_to_recurrence <= T): return True \n",
    "    elif patient_followup_time >= T: return False \n",
    "    return None \n",
    "\n",
    "def get_cohort_by_time_stamp(metadata_labels, T, verbose = 1):\n",
    "    cohort_data = {}\n",
    "    \n",
    "    indices, accession_numbers, labels = [], [], []\n",
    "    for idx, accession_number in enumerate(metadata_labels[key_subject]):\n",
    "        patient_values = metadata_labels[metadata_labels[key_subject] == accession_number]\n",
    "        patient_label =  get_patient_label(patient_date_recurrence = patient_values['date_recurrence'], \n",
    "                                           patient_date_followup =  patient_values['date_followup'],\n",
    "                                           patient_date_treatment =  patient_values['date_treatment'], \n",
    "                                           T = T*365)\n",
    "        if patient_label != None:\n",
    "            \n",
    "            indices.append(idx)\n",
    "            accession_numbers.append(accession_number)\n",
    "            labels.append(patient_label)\n",
    "        \n",
    "    if verbose > 0:\n",
    "        print('Time to recurrence: {}'.format(T))\n",
    "        print('Label Distribution: {}'.format(np.unique(labels, return_counts=True)))\n",
    "        \n",
    "    return np.array(indices), np.array(accession_numbers), np.array(labels)\n",
    "\n",
    "\n",
    "def get_cohort_features(key_subject, key_values, metadata_feature_values, metadata_clinical_metadata, modalities):\n",
    "    feature_names = [name for (name, modality) in metadata_clinical_metadata[['name', 'modality']].values if modality in modalities]\n",
    "    features_cohort = metadata_feature_values_clinical[metadata_feature_values[key_subject].isin(key_values)].copy()\n",
    "\n",
    "    return np.array(features_cohort.index.tolist()), np.array(features_cohort[key_subject].values.tolist()), features_cohort[feature_names].values, np.array(feature_names)\n",
    "\n",
    "\n",
    "def aggregate_embeddings(embedding_dict, keys):\n",
    "\n",
    "    aggregated_embeddings = []\n",
    "    for key_subject_outer in keys:\n",
    "        feature_values_imaging_subject = embedding_dict[key_subject_outer].copy()\n",
    "        feature_values_imaging_subject = np.max(feature_values_imaging_subject,  axis = 0)\n",
    "        aggregated_embeddings.append(feature_values_imaging_subject)\n",
    "        \n",
    "    return np.array(aggregated_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import deepdish as dd\n",
    "from itertools import product, combinations\n",
    "from xgboost import XGBClassifier\n",
    "exec(import_libraries(topics = ['utility', 'display', 'medical_imaging', 'image_processing']))\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import LeaveOneOut, StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = r'XXXX'\n",
    "path_images = os.path.join(path_root, 'data/images')\n",
    "path_metadata = os.path.join(path_root, 'data/metadata')\n",
    "path_metadata_clinical = os.path.join(path_metadata, 'clinical')\n",
    "path_metadata_bounding_boxes = os.path.join(path_metadata, 'bounding_boxes')\n",
    "path_metadata_dicom_headers = os.path.join(path_metadata, 'dicom_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_subject = 'accession_number'\n",
    "sequence_names_ordered = ['arterial', 'portal' ,'delayed']\n",
    "roi = 'liver0'\n",
    "model = VGG16()\n",
    "get_image_embeddings = Model(inputs=model.input, outputs=model.get_layer('fc2').output)\n",
    "encoding_method = 'integer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dicom_headers = pd.read_csv(filepath_or_buffer = os.path.join(path_metadata_dicom_headers, 'metadata.csv'), index_col = 0)\n",
    "metadata_bounding_boxes = pd.read_csv(filepath_or_buffer = os.path.join(path_metadata_bounding_boxes, 'bounding_boxes_processed.csv'))\n",
    "metadata_clinical_metadata =  pd.read_csv(filepath_or_buffer = os.path.join(path_metadata_clinical, 'clinical_metadata.csv'), index_col = 0)\n",
    "metadata_clinical_values =  pd.read_csv(filepath_or_buffer = os.path.join(path_metadata_clinical, 'clinical_values.csv'), index_col = 0)\n",
    "\n",
    "metadata_feature_values_clinical = metadata_clinical_values[[key_subject] + list(metadata_clinical_metadata[metadata_clinical_metadata['modality'] != 'target']['name'].values)].copy()\n",
    "metadata_label_values = metadata_clinical_values[[key_subject] + list(metadata_clinical_metadata[metadata_clinical_metadata['modality'] == 'target']['name'].values)].copy()\n",
    "\n",
    "for name in ['date_treatment', 'date_recurrence', 'date_followup']: \n",
    "    metadata_label_values[name] = pd.to_datetime(metadata_label_values[name])\n",
    "metadata_label_values['time_to_recurrence'] = (metadata_label_values['date_recurrence'] - metadata_label_values['date_treatment']).dt.days\n",
    "metadata_label_values['followup_time'] = (metadata_label_values['date_followup'] - metadata_label_values['date_treatment']).dt.days\n",
    "\n",
    "metadata_features_categorical = metadata_clinical_metadata[(metadata_clinical_metadata['data_type'] == 'categorical') | \n",
    "                                                           (metadata_clinical_metadata['data_type'] == 'ordinal') ].copy()\n",
    "\n",
    "for name, modality in metadata_features_categorical[['name', 'modality']].values:\n",
    "    metadata_feature_values_clinical[name] = [val.replace(' ', '')  if type(val) == str else val for val in metadata_feature_values_clinical[name]]\n",
    "    feature_values = metadata_feature_values_clinical[name].copy()\n",
    "        \n",
    "    if encoding_method == 'integer':\n",
    "        le = LabelEncoder()\n",
    "        feature_values_nans = feature_values.isna()\n",
    "        feature_values_encoded = le.fit_transform(feature_values.astype(str))\n",
    "        feature_values_encoded = [None if nan else val for (val, nan) in zip(feature_values_encoded,feature_values_nans) ]\n",
    "        metadata_feature_values_clinical[name] = feature_values_encoded\n",
    "\n",
    "metadata_key_values = metadata_label_values[key_subject].values.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_shape_z = None\n",
    "images = {}\n",
    "\n",
    "for key in tqdm_notebook(metadata_key_values):    \n",
    "    seuquence_images = [dd.io.load(os.path.join(path_images, str(key), sequence  ,'numpy_image_' + roi + '.h5')) for sequence in sequence_names_ordered]\n",
    "    \n",
    "    old_shapes, new_shape = floor_dimenssions(image_list = seuquence_images)\n",
    "    if new_shape_z != None: new_shape[0] = new_shape_z\n",
    "            \n",
    "    seuquence_images_processed = [ndimage.zoom(img, np.array(new_shape)/np.array(img.shape)) for img in seuquence_images]\n",
    "    images[key] = seuquence_images_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling and extraction of image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_size = np.arange(start=0.05, stop=0.40, step=0.05)\n",
    "filter_overlap = np.arange(start=0.03, stop=0.18, step=0.03)\n",
    "filters = np.array(list(product(filter_size, filter_overlap)))\n",
    "np.random.seed(1690811) \n",
    "filter_random_idx = np.random.choice(a=range(len(filters)), size=4, replace = False)\n",
    "pool_filter = filters[filter_random_idx]\n",
    "pool_filter = [tuple(f.astype(np.float16)) for f in pool_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pool_operator = ['iqr']\n",
    "\n",
    "embedding_dict = {}\n",
    "for c in pool_filter:\n",
    "    for p in pool_operator:\n",
    "        print(c,p)\n",
    "        combination_pooled_images = get_pooled_image_sequences(key_values = metadata_key_values,\n",
    "                                                               images = images,\n",
    "                                                               filter_size = c[0], \n",
    "                                                               filter_overlap = c[1], \n",
    "                                                               pool_op = p)\n",
    "        \n",
    "        combination_embeddings = get_vgg_embeddings(images = combination_pooled_images)\n",
    "        \n",
    "        embedding_dict[(c, p)] = dict(zip(metadata_key_values, combination_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitting_points = [1,2,3,4,5,6] \n",
    "\n",
    "feature_sets =  [['clinical'], ['clinical', 'vgg'], ['vgg']]\n",
    "\n",
    "hp_dict = {\n",
    "     'n_estimators': np.arange(start=80, stop=85, step=10),\n",
    "     'max_depth': np.arange(start=5, stop=7, step = 5).astype(int),\n",
    "     'gamma':  np.arange(start=0, stop=0.05, step=0.1),\n",
    "     'min_child_weight': np.arange(start=1.5, stop=2, step=1),\n",
    "     'max_delta_step': np.arange(start=2, stop=2.5, step=1),\n",
    "     'subsample':np.arange(start=1, stop= 1.1, step= 0.2),\n",
    "     'colsample_bytree': np.arange(start=0.8, stop=1.1, step=1),\n",
    "     'pool_filter': np.array(pool_filter),\n",
    "     'pool_operator': np.array(pool_operator),\n",
    "     'embedding_aggregation_operator': np.array(['max'])\n",
    "      }\n",
    "\n",
    "np.random.seed(123)\n",
    "for key, value in hp_dict.items():\n",
    "    if key == 'pool_filter': continue\n",
    "    sampled_hp_idx = np.random.choice(a = range(len(value)), size = 1, replace = False)\n",
    "    sampled_hp_values = np.array(value)[sampled_hp_idx]\n",
    "    hp_dict[key] = sampled_hp_values\n",
    "\n",
    "hp_keys = list(hp_dict.keys())\n",
    "hp_instruction = 'product(' + ', '.join(['hp_dict[hp_keys[' + str(i) + ']]' for i in range(len(hp_keys))]) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_results_preliminary_list = []\n",
    "    \n",
    "for modalities in tqdm_notebook(feature_sets, 'Modality'): \n",
    "    for t in tqdm_notebook(splitting_points, 'T'):\n",
    "        labels_indices, labels_key_values, labels_values = get_cohort_by_time_stamp(metadata_labels = metadata_label_values, T=t, verbose = 0)        \n",
    "\n",
    "        features_indices, features_key_values, feature_values, feature_names = get_cohort_features(key_subject = key_subject, \n",
    "                                                                                                   key_values = labels_key_values, \n",
    "                                                                                                   metadata_feature_values = metadata_feature_values_clinical, \n",
    "                                                                                                   metadata_clinical_metadata = metadata_clinical_metadata, \n",
    "                                                                                                   modalities = modalities)        \n",
    "\n",
    "        if np.all(labels_key_values == features_key_values):\n",
    "            key_values = labels_key_values.copy()\n",
    "            N=len(key_values)\n",
    "\n",
    "            print('Time Stamp:            {}'.format(t))\n",
    "            \n",
    "        else:\n",
    "            print('Error! features order doesnt match labels order')\n",
    "        number_negative_instances = np.unique(labels_values, return_counts = True)[1][0]\n",
    "        number_positive_instances = np.unique(labels_values, return_counts = True)[1][1]\n",
    "        scale_pos_weight = number_negative_instances / number_positive_instances\n",
    "\n",
    "        np.random.seed(123)\n",
    "        indices_shuffled = np.random.choice(a = range(N), size = N, replace = False)\n",
    "        labels_shuffled = labels_values[indices_shuffled].copy()\n",
    "        key_values_shuffled = key_values[indices_shuffled].copy()\n",
    "        feature_values_shuffled = feature_values[indices_shuffled, :].copy()\n",
    "        \n",
    "        loo = LeaveOneOut()\n",
    "        cv_splits_outer = list(loo.split(labels_shuffled, labels_shuffled)) \n",
    "\n",
    "        print('Fold Outer: ', end = '')\n",
    "        for fold_outer, (train_idx_outer, test_idx_outer) in tqdm_notebook(enumerate(cv_splits_outer), 'Outer'):\n",
    "\n",
    "            train_features_outer = feature_values_shuffled[train_idx_outer,:].copy()\n",
    "            train_labels_outer = labels_shuffled[train_idx_outer].copy()\n",
    "            train_key_values_outer = key_values_shuffled[train_idx_outer].copy()\n",
    "\n",
    "            test_features_outer = feature_values_shuffled[test_idx_outer,:].copy()\n",
    "            test_labels_outer = labels_shuffled[test_idx_outer].copy()\n",
    "            test_key_values_outer = key_values_shuffled[test_idx_outer].copy()   \n",
    "\n",
    "            sss = StratifiedShuffleSplit(n_splits=6, test_size=int(len(train_idx_outer)*0.1), random_state=123)\n",
    "            cv_splits_inner = list(sss.split(X=train_labels_outer,y= train_labels_outer))      \n",
    "\n",
    "            best_hyperparameters_combinaion_dict = {\n",
    "                'hyperparameters': None,\n",
    "                'metric_inner_loop': 0\n",
    "             }\n",
    "            \n",
    "            for hyperparameters in eval(hp_instruction):\n",
    "                train_features_combined_values_outer = train_features_outer.copy()\n",
    "                \n",
    "                hyperparameters = dict(zip(hp_keys, hyperparameters)) \n",
    "                hyperparameters_metric_inner_loop = 0                            \n",
    "                \n",
    "                if 'vgg' in modalities:\n",
    "                    feature_values_imaging_dict = embedding_dict[(tuple(hyperparameters['pool_filter']), hyperparameters['pool_operator'])]\n",
    "                    train_features_imaging_values_outer = aggregate_embeddings(embedding_dict = feature_values_imaging_dict, keys = train_key_values_outer)\n",
    "                    train_features_combined_values_outer = np.concatenate([train_features_combined_values_outer, train_features_imaging_values_outer], axis = 1)\n",
    "    \n",
    "                for fold_inner, (train_idx_inner, test_idx_inner) in enumerate(cv_splits_inner):\n",
    "\n",
    "                    train_features_inner = train_features_combined_values_outer[train_idx_inner,:].copy()\n",
    "                    train_labels_inner = train_labels_outer[train_idx_inner].copy()\n",
    "                    train_key_values_inner = train_key_values_outer[train_idx_inner].copy()\n",
    "\n",
    "                    test_features_inner = train_features_combined_values_outer[test_idx_inner,:].copy()\n",
    "                    test_labels_inner = train_labels_outer[test_idx_inner].copy()\n",
    "                    test_key_values_inner = train_key_values_outer[test_idx_inner].copy()\n",
    "                    \n",
    " \n",
    "                    predictor = XGBClassifier(\n",
    "                        n_estimators =  hyperparameters['n_estimators'],\n",
    "                        max_depth = hyperparameters['max_depth'],\n",
    "                        gamma = hyperparameters['gamma'],\n",
    "                        min_child_weight = hyperparameters['min_child_weight'],\n",
    "                        max_delta_step = hyperparameters['max_delta_step'],\n",
    "                        subsample = hyperparameters['subsample'],\n",
    "                        colsample_bytree = hyperparameters['colsample_bytree'],\n",
    "                        scale_pos_weight = scale_pos_weight,\n",
    "                        n_jobs= 8,\n",
    "                        random_state = 373315\n",
    "                        ) \n",
    "\n",
    "                    predictor.fit(X = train_features_inner, y = train_labels_inner)\n",
    "                    y_pred_inner = predictor.predict(test_features_inner) \n",
    "                    y_pred_proba_inner = predictor.predict_proba(test_features_inner) \n",
    "                    metric_fold = roc_auc_score(y_true=test_labels_inner, y_score=[p[1] for p in y_pred_proba_inner])\n",
    "                    \n",
    "                    hyperparameters_metric_inner_loop = hyperparameters_metric_inner_loop+metric_fold                                                \n",
    "\n",
    "                hyperparameters_metric_inner_loop = hyperparameters_metric_inner_loop/(fold_inner+1)                                          \n",
    "\n",
    "                if hyperparameters_metric_inner_loop > best_hyperparameters_combinaion_dict['metric_inner_loop']:\n",
    "                    best_hyperparameters_combinaion_dict['metric_inner_loop'] = hyperparameters_metric_inner_loop\n",
    "                    best_hyperparameters_combinaion_dict['hyperparameters'] = hyperparameters\n",
    "\n",
    "            best_hyperparameters = best_hyperparameters_combinaion_dict['hyperparameters']\n",
    "            \n",
    "            if 'vgg' in modalities:\n",
    "                feature_values_imaging_dict = embedding_dict[(tuple(best_hyperparameters['pool_filter']), best_hyperparameters['pool_operator'])]\n",
    "                train_features_imaging_values_outer = aggregate_embeddings(embedding_dict = feature_values_imaging_dict, keys = train_key_values_outer)\n",
    "                train_features_outer = np.concatenate([train_features_outer, train_features_imaging_values_outer], axis = 1)\n",
    "            \n",
    "            predictor = XGBClassifier(\n",
    "                        n_estimators = best_hyperparameters['n_estimators'],\n",
    "                        max_depth = best_hyperparameters['max_depth'],\n",
    "                        gamma = best_hyperparameters['gamma'],\n",
    "                        min_child_weight = best_hyperparameters['min_child_weight'],\n",
    "                        max_delta_step = best_hyperparameters['max_delta_step'],\n",
    "                        subsample = best_hyperparameters['subsample'],\n",
    "                        colsample_bytree = best_hyperparameters['colsample_bytree'],\n",
    "                        scale_pos_weight = scale_pos_weight,\n",
    "                        n_jobs= 8,\n",
    "                        random_state = 373315\n",
    "                        )    \n",
    "            \n",
    "            predictor.fit(X = train_features_outer, y = train_labels_outer)\n",
    "            \n",
    "            if 'vgg' in modalities:\n",
    "                test_features_imaging_values_outer = aggregate_embeddings(embedding_dict = feature_values_imaging_dict, keys = test_key_values_outer) \n",
    "                test_features_outer = np.concatenate([test_features_outer, test_features_imaging_values_outer], axis = 1)\n",
    "            \n",
    "            results_outer_loop_dict = {\n",
    "                'test_key_values_outer': str(test_key_values_outer),\n",
    "                'y_true': bool(test_labels_outer),\n",
    "                'y_pred': bool(predictor.predict(test_features_outer)),\n",
    "                'y_pred_proba': predictor.predict_proba(test_features_outer),\n",
    "                'idx': int(test_idx_outer),\n",
    "                'fold': str(np.repeat(a=fold_outer, repeats=len(test_idx_outer))),\n",
    "                'splitting_point': int(np.repeat(a=t, repeats=len(test_idx_outer))),\n",
    "                'modality': str(np.repeat(a=modalities, repeats=len(test_idx_outer))),\n",
    "                'best_hyperparameters': str(np.repeat(a=best_hyperparameters, repeats=len(test_idx_outer))),\n",
    "              }   \n",
    "             \n",
    "            results_outer_loop_dict['y_pred_proba_positive'] = float(np.repeat(a=[p[1] for p in results_outer_loop_dict['y_pred_proba']], repeats=len(test_idx_outer)))\n",
    "            final_results_preliminary_list.append(results_outer_loop_dict)\n",
    "                \n",
    "final_results = pd.DataFrame(final_results_preliminary_list)      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
